{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from PIL.ImageOps import invert\n",
    "from own_utils import remove_overlapping_junctions, non_max_suppression_fast, create_window, apply_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_intermediate = False   # set to True to show intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing\n",
    "Use the sliders to find the setting which best shows the drawn circuit, once you are satisfied press \"Enter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = '../assets/example_image.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = create_window(test_image)\n",
    "img = cv2.imread(test_image)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = apply_transformations(gray_img, tf['contrast'], tf['blur'], tf['threshold'], tf['erode'], tf['dilate'], tf['invert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_hf_model = hf_hub_download('Timdb/electronic-circuit-detection', 'components.pt')\n",
    "c_model = torch.hub.load('ultralytics/yolov5', 'custom', c_hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "c_results = c_model(img)\n",
    "\n",
    "# Print and show results\n",
    "if show_intermediate:\n",
    "    print(c_results.pandas().xyxy)\n",
    "    c_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junction inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_hf_model = hf_hub_download('Timdb/electronic-circuit-detection', 'junctions.pt')\n",
    "j_model = torch.hub.load('ultralytics/yolov5', 'custom', j_hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on the image without components\n",
    "j_results = j_model(img)\n",
    "\n",
    "# Print and show results\n",
    "if show_intermediate:\n",
    "    print(j_results.pandas().xyxy)\n",
    "    j_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove overlapping junctions\n",
    "c_coords, j_coords = remove_overlapping_junctions(j_results, c_results, overlap_threshold=0.1)\n",
    "\n",
    "# Remember the old junctions\n",
    "columns = ['xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class']\n",
    "old_j_df = pd.DataFrame(j_coords, columns=columns)\n",
    "old_c_df = pd.DataFrame(c_coords, columns=columns)\n",
    "\n",
    "# Perform non-maximum suppression on coords and junctions\n",
    "c_coords = non_max_suppression_fast(c_coords, iou_threshold=0.5)\n",
    "j_coords = non_max_suppression_fast(j_coords, iou_threshold=0.5)\n",
    "\n",
    "# Create dataframes from the components and remaining junctions\n",
    "c_df = pd.DataFrame(c_coords, columns=columns)\n",
    "j_df = pd.DataFrame(j_coords, columns=columns)\n",
    "\n",
    "if show_intermediate:\n",
    "    print(\"Old components:\")\n",
    "    print(old_c_df)\n",
    "    \n",
    "    print(\"Components:\")\n",
    "    print(c_df)\n",
    "\n",
    "    print(\"Old junctions:\")\n",
    "    print(old_j_df)\n",
    "\n",
    "    print(\"NMS Junctions:\")\n",
    "    print(j_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show final detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using c_df containing the components and j_df containing the junctions, draw all bounding boxes on the original image\n",
    "img = cv2.imread(test_image)\n",
    "c_labels = c_model.model.names\n",
    "j_labels = j_model.model.names\n",
    "\n",
    "# Draw components\n",
    "for index, row in c_df.iterrows():\n",
    "    xmin = int(row['xmin'])\n",
    "    ymin = int(row['ymin'])\n",
    "    xmax = int(row['xmax'])\n",
    "    ymax = int(row['ymax'])\n",
    "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "    label = c_labels[int(row['class'])]\n",
    "    cv2.putText(img, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "# Draw junctions\n",
    "for index, row in j_df.iterrows():\n",
    "    xmin = int(row['xmin'])\n",
    "    ymin = int(row['ymin'])\n",
    "    xmax = int(row['xmax'])\n",
    "    ymax = int(row['ymax'])\n",
    "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "\n",
    "    label = j_labels[int(row['class'])]\n",
    "    cv2.putText(img, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "# Save the image\n",
    "cv2.imwrite('../assets/output.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to generated image\n",
    "Take the final output list and generate the digital circuit based on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
