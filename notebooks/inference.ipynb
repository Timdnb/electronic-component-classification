{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from PIL.ImageOps import invert\n",
    "from own_utils import remove_overlapping_junctions, non_max_suppression_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_intermediate = False   # set to True to show intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = '../assets/example_image2.jpg'\n",
    "\n",
    "# convert to grayscale\n",
    "img = Image.open(test_image).convert('L')\n",
    "img = invert(img)\n",
    "img = ImageEnhance.Contrast(img).enhance(2)\n",
    "img = img.point(lambda p: p > 220 and 255)\n",
    "img = img.filter(ImageFilter.SMOOTH)\n",
    "\n",
    "# show image\n",
    "if show_intermediate:\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "model_path = '../models/components.pt' \n",
    "c_model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n",
    "c_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def non_max_suppression_fast(boxes, scores, iou_threshold=0.5):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    keep = []\n",
    "\n",
    "    while len(indices) > 0:\n",
    "        current = indices[0]\n",
    "        keep.append(current)\n",
    "\n",
    "        xx1 = np.maximum(x1[current], x1[indices[1:]])\n",
    "        yy1 = np.maximum(y1[current], y1[indices[1:]])\n",
    "        xx2 = np.minimum(x2[current], x2[indices[1:]])\n",
    "        yy2 = np.minimum(y2[current], y2[indices[1:]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[indices[1:]]\n",
    "\n",
    "        suppressed_indices = np.where(overlap <= iou_threshold)[0]\n",
    "\n",
    "        indices = indices[suppressed_indices + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "# Inference\n",
    "c_results = c_model(img)\n",
    "\n",
    "# Print and show results\n",
    "if show_intermediate:\n",
    "    print(c_results.pandas().xyxy)\n",
    "    c_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junction inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/junctions.pt'\n",
    "j_model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n",
    "j_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on the image without components\n",
    "j_results = j_model(img)\n",
    "\n",
    "# Print and show results\n",
    "if show_intermediate:\n",
    "    print(j_results.pandas().xyxy)\n",
    "    j_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove overlapping junctions\n",
    "c_coords, j_coords = remove_overlapping_junctions(j_results, c_results, overlap_threshold=0.1)\n",
    "\n",
    "# Remember the old junctions\n",
    "columns = ['xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class']\n",
    "old_j_df = pd.DataFrame(j_coords, columns=columns)\n",
    "old_c_df = pd.DataFrame(c_coords, columns=columns)\n",
    "\n",
    "# Perform non-maximum suppression on coords and junctions\n",
    "c_coords = non_max_suppression_fast(c_coords, iou_threshold=0.5)\n",
    "j_coords = non_max_suppression_fast(j_coords, iou_threshold=0.5)\n",
    "\n",
    "# Create dataframes from the components and remaining junctions\n",
    "c_df = pd.DataFrame(c_coords, columns=columns)\n",
    "j_df = pd.DataFrame(j_coords, columns=columns)\n",
    "\n",
    "if show_intermediate:\n",
    "    print(\"Old components:\")\n",
    "    print(old_c_df)\n",
    "    \n",
    "    print(\"Components:\")\n",
    "    print(c_df)\n",
    "\n",
    "    print(\"Old junctions:\")\n",
    "    print(old_j_df)\n",
    "\n",
    "    print(\"NMS Junctions:\")\n",
    "    print(j_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show final detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using c_df containing the components and j_df containing the junctions, draw all bounding boxes on the original image\n",
    "img = cv2.imread(test_image)\n",
    "c_labels = c_model.model.names\n",
    "j_labels = j_model.model.names\n",
    "\n",
    "# Draw components\n",
    "for index, row in c_df.iterrows():\n",
    "    xmin = int(row['xmin'])\n",
    "    ymin = int(row['ymin'])\n",
    "    xmax = int(row['xmax'])\n",
    "    ymax = int(row['ymax'])\n",
    "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "    label = c_labels[int(row['class'])]\n",
    "    cv2.putText(img, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "# Draw junctions\n",
    "for index, row in j_df.iterrows():\n",
    "    xmin = int(row['xmin'])\n",
    "    ymin = int(row['ymin'])\n",
    "    xmax = int(row['xmax'])\n",
    "    ymax = int(row['ymax'])\n",
    "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "\n",
    "    label = j_labels[int(row['class'])]\n",
    "    cv2.putText(img, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "# Save the image\n",
    "cv2.imwrite('../assets/output.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to generated image\n",
    "Take the final output list and generate the digital circuit based on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
